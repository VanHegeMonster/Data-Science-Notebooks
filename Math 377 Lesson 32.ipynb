{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from math import *\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 32: Likelihood Ratio Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we introduced Likelihood Ratio tests. Recall that the point of a likelihood ratio test is to compare the likelihood function under a hypothesized value of the parameter with the liklihood function at its maximum. Instead of looking at the ratio $\\Lambda$ itself, we often consider $-2\\log \\Lambda$ instead, since it has a handy distribution. \n",
    "\n",
    "### Example 1: Exponential Distribution\n",
    "\n",
    "Suppose $X_1,X_2,...,X_n$ is an iid sequence of random variables from the exponential distribution with unknown parameter $\\lambda$. Recall that the maximum likelihood estimate of $\\lambda$ is $1\\over\\bar{X}$. We collect a random sample of size 20 and want to test the hypothesis $H_0: \\lambda = 3$ vs $H_1: \\lambda \\neq 3$. Using the data in the python box below, conduct a likelihood ratio test on this hypothesis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=np.array([0.18,0.277,0.105,0.126,0.225,0.026,0.123,0.423,0.006,0.281,0.050,0.692,0.105,0.275,0.346,0.079,0.045,0.222,0.063,0.281])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=20, minmax=(0.006, 0.692), mean=0.1965, variance=0.027176368421052633, skewness=1.3751532772375619, kurtosis=2.0594082496235426)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe the data\n",
    "stats.describe(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.089058524173028\n"
     ]
    }
   ],
   "source": [
    "#Start by finding ML of the data\n",
    "mu=np.mean(my_data) #mean of the data\n",
    "Lambda_ML=1/(np.mean(my_data))\n",
    "print(Lambda_ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279807.44620464457\n",
      "279807.4462046449\n",
      "0.09445694279678163\n"
     ]
    }
   ],
   "source": [
    "Likelihood_ML=np.prod(Lambda_ML*e**(-Lambda_ML*my_data)) #one way to do it\n",
    "print(Likelihood_ML)\n",
    "Likeilhood_ML_2=Lambda_ML**20*e**(-20*Lambda_ML*mu) #Another way to do it\n",
    "print(Likeilhood_ML_2)\n",
    "Likelihood_3=np.prod(3*e**(-3*my_data))\n",
    "Capital_Lambda=Likelihood_3/Likelihood_ML\n",
    "print(Capital_Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic of -2log(Lambda): 4.719222360188457\n"
     ]
    }
   ],
   "source": [
    "print('Test statistic of -2log(Lambda):',-2*log(Capital_Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02982722919477517"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now our next question is: what is the probability we get a test statistic of above?\n",
    "p_value=stats.chi2.sf(-2*log(Capital_Lambda),1) #survival function (equivalent to 1-cdf)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Suppose that the true value of $\\lambda$ is 5. Let's determine the power of this test. Let $n=20$. Then determine the power if $n=50$. Remember, power is the probability of correctly rejecting the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, find what value of $-2 \\log \\Lambda$ would lead you to reject $H_0$. This is sometimes called the critical value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.841458820694124"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critical_value=stats.chi2.ppf(.95,1)\n",
    "critical_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, obtain the power. Obtain a sample of size 20 from the true population and obtain the value of $-2\\log \\Lambda$ for this sample. Repeat many times and determine how often you reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5968"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reject=[]\n",
    "for i in np.arange(100000):\n",
    "    minisample=stats.expon.rvs(size=20,scale=1/5) #This is considered the true population\n",
    "    mu_sample=np.mean(minisample)\n",
    "    lamb_sample=1/mu_sample\n",
    "    Likelihood_3=np.prod(3*e**(-3*minisample))\n",
    "    Likelihood_ML=np.prod(lamb_sample*e**(-lamb_sample*minisample))\n",
    "    Reject=np.append(Reject,-2*log(Likelihood_3/Likelihood_ML)>=critical_value)\n",
    "np.mean(Reject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that for a sample of size 20, we correctly reject the null around 60 percent of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. What do you expect to happen to power? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect to reject the null significantly more times than with a sample size of 20. As a result, we expect to correctly reject the null a far greater percent of the time compared to a sample with a size of 20. As a result, the power increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reject=[] \n",
    "\n",
    "for i in np.arange(10000):\n",
    "    minisample=stats.expon.rvs(size=50,scale=1/5) #This is considered the true population (size here is 50)\n",
    "    mu_sample=np.mean(minisample)\n",
    "    lamb_sample=1/mu_sample\n",
    "    Likelihood_3=np.prod(3*e**(-3*minisample))\n",
    "    Likelihood_ML=np.prod(lamb_sample*e**(-lamb_sample*minisample))\n",
    "    Reject=np.append(Reject,-2*log(Likelihood_3/Likelihood_ML)>=critical_value)\n",
    "np.mean(Reject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a hard topic to concieve, let's do another test and let $\\lambda$ be 5, that of the true value of the population and determine how many times we reject this \"new\" test statistic. That is, for the purposes of argument, let $H_0=5$ and perform the statistic as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0492"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reject=[] \n",
    "\n",
    "for i in np.arange(10000):\n",
    "    minisample=stats.expon.rvs(size=50,scale=1/5) #This is considered the true population (size here is 50)\n",
    "    mu_sample=np.mean(minisample)\n",
    "    lamb_sample=1/mu_sample\n",
    "    Likelihood_5=np.prod(5*e**(-5*minisample)) #Note the change\n",
    "    Likelihood_ML=np.prod(lamb_sample*e**(-lamb_sample*minisample))\n",
    "    Reject=np.append(Reject,-2*log(Likelihood_5/Likelihood_ML)>=critical_value)\n",
    "np.mean(Reject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, we've only rejected this \"new\" $H_0$ around 5% of the time. Which, when looking above, given a true value of the system and comparing it, we've found ourselves computing the probability of a Type II error, that is, $\\beta$ or how many times we've incorrectly rejected the null when the null was true. This is almost starting to make sense... but not quite yet.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Different Test\n",
    "\n",
    "We've explored hypothesis tests in this class before. Taking advantage of our computing power, we don't have to rely on test statistics with asymptotic distributions. Let's conduct a more direct hypothesis test using simulation. Recall:\n",
    "\n",
    "$$\n",
    "H_0: \\lambda = 3\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_1: \\lambda \\neq 3\n",
    "$$\n",
    "\n",
    "Pick a different test statistic. Obtain an empirical distribution of that test statistic under $H_0$. Next, find the $p$-value by determining how often this test statistic is at or further away from the test statistic derived from the sample. Remember that this is a two-sided test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "I've added the bold.. because I could. We proceed. Since the problem states to pick a different test statistic, but then tells you which one to use, we will use the one we are supposed to use. That is, how often, with an emperical distribution, do we get values further away than the test statistic. Let's be kind to ourselves: the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this down into nice breaks and steps. First, let's simulate under the null hypothesis (ie create a data set knowing this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3647005293216873 0.3096111241867293 0.30754938965125134\n"
     ]
    }
   ],
   "source": [
    "Simulated=np.array([np.mean(stats.expon.rvs(size=20,scale=1/3)) for _ in np.arange(10000)])\n",
    "print(Simulated[1],Simulated[2],Simulated[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a set of simulated data, specifically the mean. Now, let's find the mean of the empirical data we have (the mean of my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1965\n"
     ]
    }
   ],
   "source": [
    "mu_data=np.mean(my_data)\n",
    "print(mu_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where a nuance steps in, the average for the simulated should by 1/3, as determined by the maximum likelihood of a set with an exponential distribution. So, how many times is our simulated data set further away from 1/3 than 1/3 is from the $\\mu_{my_{data}}$. So we are looking for, how many times is the simulated data set less than $\\mu_{my_{data}}$ or .1965 and greater than 1/3+.1965. We proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    }
   ],
   "source": [
    "p=np.mean((Simulated)<0.1965)+np.mean(Simulated>(.1965+1/3))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the $p$-value compare to the LRT $p$-value? I wonder how the power of this test compares to our LRT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This p value is $\\approx$.03, which is slightly less of a p value than our LRT. This would imply we reject the null hypothesis. We proceed to determining the power of this test..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Let's figure out the power of this test. First, determine for what values of the test statistic would lead us to reject $H_0$. These values can be referred to as your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20248883098477966\n",
      "0.49512571375250003\n"
     ]
    }
   ],
   "source": [
    "#for the sample data, we are setting the upper and lower bounds.\n",
    "Simulated=np.array([np.mean(stats.expon.rvs(size=20,scale=1/3)) for _ in np.arange(10000)])\n",
    "Lower=percentile(2.5,Simulated)\n",
    "Upper=percentile(97.5,Simulated)\n",
    "print(Lower)\n",
    "print(Upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, determine the power of this test. Like in the LRT case, obtain a sample of size 20 and obtain the test statistic. Repeat many times and see how often your test statistic is in your rejection region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the change in scale to 1/5 instead of 1/3. We, in this case are assuming the alternative is true, so $\\lambda$=5 is assumed true. How often, do we therefore reject the null when we are supposed to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5507\n"
     ]
    }
   ],
   "source": [
    "Simulated=np.array([np.mean(stats.expon.rvs(size=20,scale=1/5)) for _ in np.arange(10000)])\n",
    "p=np.mean(Simulated<=Lower)+np.mean(Simulated>=Upper)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. Note that you will have to obtain new critical values in order to do this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24773668908547097 0.43063758219494497\n"
     ]
    }
   ],
   "source": [
    "Simulated=np.array([np.mean(stats.expon.rvs(size=50,scale=1/3)) for _ in np.arange(10000)])\n",
    "Lower=percentile(2.5,Simulated)\n",
    "Upper=percentile(97.5,Simulated)\n",
    "print(Lower,Upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how often, with a sample size of 50, do we properly reject the null when we are supposed to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948\n"
     ]
    }
   ],
   "source": [
    "Simulated=np.array([np.mean(stats.expon.rvs(size=50,scale=1/5)) for _ in np.arange(10000)])\n",
    "p50=np.mean(Simulated<=Lower)+np.mean(Simulated>=Upper)\n",
    "print(p50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, we've greatly improved the power of the test by merely increasing the sample size by 2.5 times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
